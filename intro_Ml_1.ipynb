{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 Explain the following with an example:\n",
    "- 1) Artificial Intelligence\n",
    "- 2) Machine Learning\n",
    "- 3) Deep Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Artificial Intelligence (AI)\n",
    "**Definition**: Artificial Intelligence refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. It encompasses a broad range of techniques that enable machines to perform tasks that typically require human intelligence, such as speech recognition, decision-making, visual perception, and language translation.\n",
    "\n",
    "**Example**: One notable example of AI is IBM's Watson. Watson is an AI system that processes vast amounts of natural language data to answer questions posed in natural language. It has been used in various applications, including healthcare diagnostics, financial analysis, and customer service.\n",
    "\n",
    "### 2) Machine Learning (ML)\n",
    "**Definition**: Machine Learning is a subset of AI that focuses on the development of algorithms and statistical models that allow computers to learn from and make predictions or decisions based on data. It enables machines to improve their performance on tasks over time without being explicitly programmed.\n",
    "\n",
    "**Example**: An example of machine learning is email spam filtering. Machine learning algorithms can be trained on labeled data (emails labeled as spam or not spam) to learn patterns that distinguish between spam and legitimate emails. Once trained, the model can classify new emails as either spam or not spam based on its learned patterns.\n",
    "\n",
    "### 3) Deep Learning\n",
    "**Definition**: Deep Learning is a subfield of machine learning that involves artificial neural networks (ANNs) with multiple layers (hence \"deep\"). It aims to model high-level abstractions in data by using multiple layers of nonlinear processing units for feature extraction and transformation. Deep learning has been instrumental in achieving state-of-the-art performance in various tasks such as image and speech recognition.\n",
    "\n",
    "**Example**: A common example of deep learning is image classification using Convolutional Neural Networks (CNNs). CNNs are deep learning models specifically designed to process visual data. For instance, a CNN can be trained on a dataset of images labeled with different objects (e.g., cats, dogs, cars) to learn to recognize and classify new images based on their visual features.\n",
    "\n",
    "These explanations illustrate how Artificial Intelligence, Machine Learning, and Deep Learning differ in scope and application, each playing a significant role in advancing technology and solving complex problems across various domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2 What is supervised learning ? List some examples of supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "**Definition:** Supervised learning is a type of machine learning where the model is trained on a labeled dataset, which means the dataset includes input-output pairs. The goal is for the model to learn the mapping between the input variables (features) and the target variable (output) so that it can generalize to make predictions on new, unseen data.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "- Labeled Data: Supervised learning requires labeled data, where each example in the training dataset is associated with a known output or target.\n",
    "- Training Process: During training, the model adjusts its parameters to minimize the difference between its predictions and the actual labels in the training data.\n",
    "- Types of Tasks: Supervised learning can be used for both classification (predicting a categorical label) and regression (predicting a continuous value) tasks.\n",
    "### Examples of Supervised Learning\n",
    "**Email Spam Classification:**\n",
    "\n",
    "- Task: Classifying emails as spam or not spam.\n",
    "- Example: Using a labeled dataset of emails where each email is labeled as spam or not spam, a supervised learning algorithm (e.g., Naive Bayes, Support Vector Machine) can be trained to classify new emails.\n",
    "### Handwritten Digit Recognition:\n",
    "\n",
    "- Task: Recognizing handwritten digits (0-9).\n",
    "- Example: Using a dataset like MNIST, which contains images of handwritten digits along with their corresponding labels, a supervised learning algorithm (e.g., Convolutional Neural Network) can be trained to recognize and classify new handwritten digits.\n",
    "### Predicting Housing Prices:\n",
    "\n",
    "- Task: Predicting the selling price of a house based on its features (e.g., location, size, number of rooms).\n",
    "- Example: Using a dataset of housing prices where each entry includes features of the house and its actual selling price, a supervised learning algorithm (e.g., Linear Regression, Decision Tree) can be trained to predict the price of new houses.\n",
    "### Medical Diagnosis:\n",
    "\n",
    "- Task: Diagnosing a disease based on patient symptoms and medical test results.\n",
    "- Example: Using a dataset of patient records where each record includes symptoms, test results, and the diagnosed disease, a supervised learning algorithm (e.g., Support Vector Machine, Neural Network) can be trained to assist in medical diagnosis.\n",
    "### Sentiment Analysis:\n",
    "\n",
    "- Task: Classifying the sentiment of text (positive, negative, neutral).\n",
    "- Example: Using a dataset of movie reviews labeled with sentiments (positive or negative), a supervised learning algorithm (e.g., Recurrent Neural Network, Naive Bayes) can be trained to classify the sentiment of new reviews.\n",
    "\n",
    "*These examples demonstrate how supervised learning algorithms can be applied across various domains to solve classification and regression problems using labeled data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 What is unsupervised learning ? List some examples of unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning\n",
    "**Definition:** Unsupervised learning is a type of machine learning where the model is trained on unlabeled data. Unlike supervised learning, there are no predefined output labels for the input data. The goal of unsupervised learning is to find hidden patterns or intrinsic structures in the data.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "- Unlabeled Data: Unsupervised learning algorithms work with data that lacks explicit labels or predefined outputs.\n",
    "- Objective: The main objective is to discover the underlying structure or distribution in the data without guidance from a specific output variable.\n",
    "- Types of Tasks: Unsupervised learning tasks include clustering, dimensionality reduction, and density estimation.\n",
    "### Examples of Unsupervised Learning\n",
    "- **Clustering:**\n",
    "\n",
    "    - **Task:** Grouping similar instances together into clusters.\n",
    "    - **Example:** Using customer purchase data where each transaction is represented by features (e.g., items purchased, time of purchase), unsupervised learning algorithms (e.g., K-means clustering, DBSCAN) can be used to cluster customers into segments based on their purchasing behavior.\n",
    "- **Anomaly Detection:**\n",
    "\n",
    "    - **Task:** Identifying unusual or abnormal instances in the data.\n",
    "    - **Example:** Monitoring network traffic data to detect unusual patterns that might indicate a cyber attack. Unsupervised learning algorithms (e.g., Isolation Forest, One-Class SVM) can be used to identify anomalies in the absence of labeled attack data.\n",
    "- **Dimensionality Reduction:**\n",
    "\n",
    "    - **Task:** Reducing the number of variables or features in the data.\n",
    "    - **Example:** Using techniques like Principal Component Analysis (PCA) or t-SNE, unsupervised learning can reduce the dimensionality of high-dimensional data (e.g., images, genetic data) while preserving important relationships and structures.\n",
    "- **Topic Modeling:**\n",
    "\n",
    "    - **Task:** Identifying topics or themes in a collection of text documents.\n",
    "    - **Example:** Analyzing a large corpus of news articles to automatically identify topics such as politics, sports, and entertainment. Unsupervised learning algorithms (e.g., Latent Dirichlet Allocation) can be used to uncover latent topics without prior knowledge of the topics.\n",
    "- **Association Rule Learning:**\n",
    "\n",
    "    - **Task:** Discovering interesting relationships or associations between variables in large databases.\n",
    "    - **Example:** Analyzing customer transaction data to uncover relationships between purchased items. Unsupervised learning algorithms (e.g., Apriori algorithm) can generate association rules that describe the co-occurrence patterns of items bought together.\n",
    "   \n",
    "*These examples illustrate how unsupervised learning techniques can be applied to explore and extract meaningful insights from data without the need for labeled examples, making it a valuable approach for tasks where labeled data is scarce or unavailable.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 What is difference between AI,ML,DL and DS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences between AI, ML, DL, and DS\n",
    "\n",
    "### Artificial Intelligence (AI)\n",
    "AI is the broadest concept, encompassing the creation of intelligent machines that can simulate human-like behavior and decision-making.\n",
    "\n",
    "- **Scope**: Covers a wide range of techniques and approaches\n",
    "- **Goal**: To create systems that can perform tasks requiring human-like intelligence\n",
    "- **Examples**: Natural language processing, robotics, expert systems\n",
    "\n",
    "### Machine Learning (ML)\n",
    "ML is a subset of AI that focuses on developing algorithms and statistical models that enable computers to improve their performance on a task through experience.\n",
    "\n",
    "- **Scope**: Narrower than AI, focusing on data-driven approaches\n",
    "- **Goal**: To enable systems to learn and improve from experience without being explicitly programmed\n",
    "- **Examples**: Decision trees, support vector machines, clustering algorithms\n",
    "\n",
    "### Deep Learning (DL)\n",
    "DL is a specialized subset of ML that uses artificial neural networks with multiple layers (deep neural networks) to model and process complex patterns in data.\n",
    "\n",
    "- **Scope**: More specific than ML, focusing on neural network architectures\n",
    "- **Goal**: To automatically learn hierarchical representations of data\n",
    "- **Examples**: Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs)\n",
    "\n",
    "### Data Science (DS)\n",
    "DS is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data.\n",
    "\n",
    "- **Scope**: Broader than ML and DL, incorporating elements from statistics, computer science, and domain expertise\n",
    "- **Goal**: To extract actionable insights from data to solve complex problems and inform decision-making\n",
    "- **Examples**: Data visualization, statistical analysis, predictive modeling\n",
    "\n",
    "### Relationship\n",
    "- AI is the overarching field\n",
    "- ML is a subset of AI\n",
    "- DL is a subset of ML\n",
    "- DS overlaps with AI, ML, and DL but also includes additional elements like data preprocessing, visualization, and domain-specific analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 What are the main difference between supervised , unsupervised learning and semi-supervised learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Differences: Supervised, Unsupervised, and Semi-Supervised Learning\n",
    "\n",
    "### Supervised Learning\n",
    "\n",
    "- **Definition**: Learning from labeled data\n",
    "- **Input Data**: Labeled dataset (features and corresponding target variables)\n",
    "- **Goal**: Predict outcomes for new, unseen data\n",
    "- **Process**:\n",
    "    1. Model learns from labeled training data\n",
    "    2. Model is evaluated on test data\n",
    "    3. Model makes predictions on new data\n",
    "- **Examples**: \n",
    "    - Classification (e.g., spam detection)\n",
    "    - Regression (e.g., house price prediction)\n",
    "- **Algorithms**: \n",
    "    - Linear Regression\n",
    "    - Logistic Regression\n",
    "    - Support Vector Machines\n",
    "    - Random Forests\n",
    "\n",
    "### Unsupervised Learning\n",
    "\n",
    "- **Definition**: Learning from unlabeled data\n",
    "- **Input Data**: Unlabeled dataset (features only, no target variables)\n",
    "- **Goal**: Discover hidden patterns or structures in data\n",
    "- **Process**:\n",
    "    1. Model explores data to find inherent structures\n",
    "    2. Model groups or organizes data based on discovered patterns\n",
    "- **Examples**:\n",
    "    - Clustering\n",
    "    - Dimensionality reduction\n",
    "    - Anomaly detection\n",
    "- **Algorithms**:\n",
    "    - K-means clustering\n",
    "    - Hierarchical clustering\n",
    "    - Principal Component Analysis (PCA)\n",
    "    - Autoencoders\n",
    "\n",
    "### Semi-Supervised Learning\n",
    "\n",
    "- **Definition**: Learning from a combination of labeled and unlabeled data\n",
    "- **Input Data**: Partially labeled dataset (some data points have labels, others don't)\n",
    "- **Goal**: Improve learning accuracy using both labeled and unlabeled data\n",
    "- **Process**:\n",
    "    1. Model learns from labeled data\n",
    "    2. Model uses learned patterns to label unlabeled data\n",
    "    3. Model continues learning with newly labeled data\n",
    "- **Examples**:\n",
    "    - Text classification with some labeled documents\n",
    "    - Image recognition with partially labeled image sets\n",
    "- **Algorithms**:\n",
    "    - Self-training\n",
    "    - Multi-view learning\n",
    "    - Graph-based methods\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "1. **Data Labeling**:\n",
    "   - Supervised: Fully labeled data\n",
    "   - Unsupervised: No labeled data\n",
    "   - Semi-supervised: Partially labeled data\n",
    "\n",
    "2. **Cost and Time**:\n",
    "   - Supervised: Most expensive and time-consuming (due to labeling)\n",
    "   - Unsupervised: Least expensive and time-consuming\n",
    "   - Semi-supervised: Moderate cost and time\n",
    "\n",
    "3. **Accuracy**:\n",
    "   - Supervised: Generally highest accuracy\n",
    "   - Unsupervised: Lower accuracy, but can uncover unknown patterns\n",
    "   - Semi-supervised: Potentially higher accuracy than unsupervised, especially with limited labeled data\n",
    "\n",
    "4. **Flexibility**:\n",
    "   - Supervised: Limited to predefined categories\n",
    "   - Unsupervised: Most flexible, can adapt to unknown patterns\n",
    "   - Semi-supervised: Balances between predefined categories and new patterns\n",
    "\n",
    "5. **Use Cases**:\n",
    "   - Supervised: When outcomes are known and data can be fully labeled\n",
    "   - Unsupervised: When exploring data structure or reducing dimensionality\n",
    "   - Semi-supervised: When partial labeling is available or affordable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6  What is train test and validation split ? Explain importance of each term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Validation Split\n",
    "\n",
    "The train-test-validation split is a technique used in machine learning to assess the performance of a model and prevent overfitting. It involves dividing the available data into three subsets:\n",
    "\n",
    "### 1. Training Set\n",
    "\n",
    "- **Purpose**: Used to train the model\n",
    "- **Size**: Typically 60-80% of the total data\n",
    "- **Importance**:\n",
    "  - Provides the data from which the model learns patterns and relationships\n",
    "  - Allows the model to adjust its parameters and improve its performance\n",
    "  - Larger training sets generally lead to better model performance, especially for complex models\n",
    "\n",
    "### 2. Validation Set\n",
    "\n",
    "- **Purpose**: Used for tuning model hyperparameters and selecting the best model\n",
    "- **Size**: Typically 10-20% of the total data\n",
    "- **Importance**:\n",
    "  - Helps in model selection and hyperparameter tuning without touching the test set\n",
    "  - Prevents overfitting to the training data by providing an independent set for evaluation during the training process\n",
    "  - Allows for early stopping in iterative algorithms to prevent overfitting\n",
    "\n",
    "### 3. Test Set\n",
    "\n",
    "- **Purpose**: Used to evaluate the final model's performance\n",
    "- **Size**: Typically 10-20% of the total data\n",
    "- **Importance**:\n",
    "  - Provides an unbiased evaluation of the final model's performance\n",
    "  - Simulates how the model would perform on unseen data in real-world scenarios\n",
    "  - Helps assess if the model has generalized well from the training data\n",
    "\n",
    "### Importance of the Split\n",
    "\n",
    "1. **Prevents Overfitting**: \n",
    "   - By evaluating on separate validation and test sets, we can detect if the model is memorizing the training data rather than learning general patterns.\n",
    "\n",
    "2. **Reliable Performance Estimation**: \n",
    "   - The test set provides an unbiased estimate of the model's performance on new, unseen data.\n",
    "\n",
    "3. **Model Selection**: \n",
    "   - The validation set allows for comparison between different models or hyperparameter configurations without compromising the integrity of the test set.\n",
    "\n",
    "4. **Generalization Assessment**: \n",
    "   - By comparing performance across all three sets, we can assess how well the model generalizes to new data.\n",
    "\n",
    "5. **Confidence in Results**: \n",
    "   - A proper split increases confidence in the model's real-world performance and helps in making informed decisions about model deployment.\n",
    "\n",
    "### Common Variations\n",
    "\n",
    "- **K-Fold Cross-Validation**: Useful when data is limited, involving multiple rounds of training and validation on different subsets of the data.\n",
    "- **Stratified Split**: Ensures that the proportion of samples for each class is roughly the same in each set, useful for imbalanced datasets.\n",
    "- **Time Series Split**: For time-dependent data, where the split respects the temporal order of the data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7 How can Unsupervised Learning be used in anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning in Anomaly Detection\n",
    "\n",
    "Unsupervised learning is particularly well-suited for anomaly detection because it can identify unusual patterns in data without prior knowledge of what constitutes an anomaly. Here are some key ways unsupervised learning is used in anomaly detection:\n",
    "\n",
    "## 1. Clustering-Based Methods\n",
    "\n",
    "### K-means Clustering\n",
    "- **Approach**: Group data points into K clusters\n",
    "- **Anomaly Detection**: Points far from cluster centers or in small clusters are potential anomalies\n",
    "- **Use Case**: Detecting unusual behavior in network traffic\n",
    "\n",
    "### DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
    "- **Approach**: Group data points based on density\n",
    "- **Anomaly Detection**: Points not assigned to any cluster are considered anomalies\n",
    "- **Use Case**: Identifying fraudulent transactions in financial data\n",
    "\n",
    "## 2. Dimensionality Reduction Techniques\n",
    "\n",
    "### Principal Component Analysis (PCA)\n",
    "- **Approach**: Reduce data dimensionality while preserving variance\n",
    "- **Anomaly Detection**: Data points with high reconstruction error are potential anomalies\n",
    "- **Use Case**: Detecting anomalies in high-dimensional sensor data\n",
    "\n",
    "### Autoencoders\n",
    "- **Approach**: Neural network learns to compress and reconstruct data\n",
    "- **Anomaly Detection**: High reconstruction error indicates potential anomalies\n",
    "- **Use Case**: Identifying unusual patterns in image or time series data\n",
    "\n",
    "## 3. Statistical Methods\n",
    "\n",
    "### Gaussian Mixture Models (GMM)\n",
    "- **Approach**: Model data as a mixture of Gaussian distributions\n",
    "- **Anomaly Detection**: Points with low probability under the model are potential anomalies\n",
    "- **Use Case**: Detecting anomalies in continuous, multi-modal data\n",
    "\n",
    "### Isolation Forest\n",
    "- **Approach**: Isolate anomalies rather than profiling normal points\n",
    "- **Anomaly Detection**: Points that are easy to isolate are considered anomalies\n",
    "- **Use Case**: Efficient anomaly detection in large-scale datasets\n",
    "\n",
    "## 4. One-Class Support Vector Machines (SVM)\n",
    "- **Approach**: Learn a boundary that encompasses most of the normal data\n",
    "- **Anomaly Detection**: Points outside this boundary are considered anomalies\n",
    "- **Use Case**: Detecting novelties in data with a well-defined \"normal\" class\n",
    "\n",
    "## 5. Self-Organizing Maps (SOM)\n",
    "- **Approach**: Create a low-dimensional representation of the input space\n",
    "- **Anomaly Detection**: Identify neurons with high quantization error or low activation frequency\n",
    "- **Use Case**: Visualizing and detecting anomalies in high-dimensional data\n",
    "\n",
    "## Advantages of Unsupervised Learning for Anomaly Detection\n",
    "\n",
    "1. **No labeled data required**: Can work with unlabeled datasets, which are often more abundant and easier to obtain\n",
    "2. **Adaptability**: Can detect novel types of anomalies not seen before\n",
    "3. **Continuous learning**: Can update models as new data becomes available\n",
    "4. **Versatility**: Applicable across various domains and data types\n",
    "\n",
    "## Challenges\n",
    "\n",
    "1. **Defining \"normal\"**: Determining the threshold for what constitutes an anomaly can be subjective\n",
    "2. **Handling high-dimensional data**: Some methods may struggle with the curse of dimensionality\n",
    "3. **Interpretability**: Some models (e.g., deep learning-based) may lack easy interpretability\n",
    "4. **Computational complexity**: Some methods may be computationally intensive for large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8 List down some commonly used supervised learning algorithms and unsupervised learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commonly Used Machine Learning Algorithms\n",
    "\n",
    "### Supervised Learning Algorithms\n",
    "\n",
    "1. **Linear Regression**\n",
    "   - Used for predicting continuous values\n",
    "   - Examples: Price prediction, sales forecasting\n",
    "\n",
    "2. **Logistic Regression**\n",
    "   - Used for binary classification problems\n",
    "   - Examples: Spam detection, customer churn prediction\n",
    "\n",
    "3. **Decision Trees**\n",
    "   - Versatile algorithm for both classification and regression\n",
    "   - Examples: Customer segmentation, medical diagnosis\n",
    "\n",
    "4. **Random Forest**\n",
    "   - Ensemble method using multiple decision trees\n",
    "   - Examples: Feature importance ranking, image classification\n",
    "\n",
    "5. **Support Vector Machines (SVM)**\n",
    "   - Effective for high-dimensional spaces\n",
    "   - Examples: Text classification, image recognition\n",
    "\n",
    "6. **Naive Bayes**\n",
    "   - Based on Bayes' theorem with independence assumptions\n",
    "   - Examples: Spam filtering, sentiment analysis\n",
    "\n",
    "7. **K-Nearest Neighbors (KNN)**\n",
    "   - Instance-based learning for classification and regression\n",
    "   - Examples: Recommendation systems, pattern recognition\n",
    "\n",
    "8. **Gradient Boosting Algorithms**\n",
    "   - XGBoost, LightGBM, CatBoost\n",
    "   - Examples: Ranking, click-through rate prediction\n",
    "\n",
    "9. **Neural Networks**\n",
    "   - Deep learning models for complex patterns\n",
    "   - Examples: Image and speech recognition, natural language processing\n",
    "\n",
    "10. **Elastic Net**\n",
    "    - Combines L1 and L2 regularization\n",
    "    - Examples: Feature selection, genomic data analysis\n",
    "\n",
    "### Unsupervised Learning Algorithms\n",
    "\n",
    "1. **K-Means Clustering**\n",
    "   - Partitions data into K clusters\n",
    "   - Examples: Customer segmentation, image compression\n",
    "\n",
    "2. **Hierarchical Clustering**\n",
    "   - Creates a tree of clusters\n",
    "   - Examples: Taxonomies, document clustering\n",
    "\n",
    "3. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**\n",
    "   - Clusters based on density of data points\n",
    "   - Examples: Spatial data analysis, anomaly detection\n",
    "\n",
    "4. **Principal Component Analysis (PCA)**\n",
    "   - Dimensionality reduction technique\n",
    "   - Examples: Feature extraction, data visualization\n",
    "\n",
    "5. **Independent Component Analysis (ICA)**\n",
    "   - Separates multivariate signal into additive components\n",
    "   - Examples: Signal processing, feature extraction\n",
    "\n",
    "6. **t-SNE (t-Distributed Stochastic Neighbor Embedding)**\n",
    "   - Visualization of high-dimensional data\n",
    "   - Examples: Visualizing word embeddings, exploring complex datasets\n",
    "\n",
    "7. **Autoencoders**\n",
    "   - Neural network for dimensionality reduction and feature learning\n",
    "   - Examples: Image denoising, anomaly detection\n",
    "\n",
    "8. **Gaussian Mixture Models**\n",
    "   - Probabilistic model for representing normally distributed subpopulations\n",
    "   - Examples: Speech recognition, image segmentation\n",
    "\n",
    "9. **Apriori Algorithm**\n",
    "   - Association rule learning for discovering relations between variables\n",
    "   - Examples: Market basket analysis, web usage mining\n",
    "\n",
    "10. **Self-Organizing Maps (SOM)**\n",
    "    - Type of artificial neural network for dimensionality reduction\n",
    "    - Examples: Visualizing high-dimensional data, clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
